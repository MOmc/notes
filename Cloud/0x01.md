# Flaws.cloud

- **Level 1**
	- When hosting a site as an S3 bucket, the bucket name (flaws.cloud) must match the domain name (flaws.cloud).
	-  S3 buckets are a global name space, meaning two people cannot have buckets with the same name.
	- you could create a bucket named apple.com and Apple would never be able host their main site via S3 hosting.
	- You can determine the site is hosted as an S3 bucket by running a DNS lookup on the domain,
	- `dig +nocmd domainname any +multiline +noall +answer`
	- Go to `A`  listed IP  in the browser it should redirect it to `https://aws.amazon.com/s3/`
	- It gives an indication that a bucket has been created by someone with the same name as the domain. 
	- `nslookup` on the `IP Address` will reveal the full domain address of the bucket.

	-  See `nslookup 54.231.184.255`
	- All S3 buckets, when configured for web hosting, are given an AWS domain you can use to browse to it without setting up your own DNS. In this case, flaws.cloud can also be visited by going to `http://flaws.cloud.s3-website-us-west-2.amazonaws.com/`
	-  Use `aws  cli` to interact with the bucket 
		-  `pip install was-cli`
	- Region is also important to supply in the command
	- `aws s3 ls  s3://flaws.cloud/ --no-sign-request --region us-west-2`
	- If you happened to not know the region, there are only a dozen regions to try. You could also use the GUI tool cyberduck to browse this bucket and it will figure out the region automatically.
	- Note that according to the documentation there are only a limited number of regions. Hence bruteforcing this with the table below could work. Moreover, the command works in this case without specifying the region.
	- On AWS you can set up S3 buckets with all sorts of permissions and functionality including using them to host static files. A number of people accidentally open them up with permissions that are too loose. Just like how you shouldn't allow directory listings of web servers, you shouldn't allow bucket listings.
	- By default, S3 buckets are private and secure when they are created. To allow it to be accessed as a web page, I had turn on "Static Website Hosting" and changed the bucket policy to allow everyone "s3:GetObject" privileges, which is fine if you plan to publicly host the bucket as a web page. But then to introduce the flaw, I changed the permissions to add "Everyone" to have "List" permissions.
	- "Everyone" means everyone on the Internet. You can also list the files simply by going to http://flaws.cloud.s3.amazonaws.com/ due to that List permission.
	-  you can also just visit http://flaws.cloud.s3.amazonaws.com/ which lists the files due to the permissions issues on this bucket.

- **Level 2**
	- Create an IAM admin user 
	- `aws s3 --profile YOUR_ACCOUNT ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud`
	- `aws s3 --profile Flawer ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud/`
	- http://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/
	- Similar to opening permissions to "Everyone", people accidentally open permissions to "Any Authenticated AWS User". They might mistakenly think this will only be users of their account, when in fact it means anyone that has an AWS account.

- **Level 3**
	- 
		
